}
penguins
for (i in 1:C){
if(type_column[i] == 'factor'){
penguins = penguins %>%relocate(colnames(penguins)[i], .after = last_col())
}
}
penguins
for (i in 1:C){
if(type_column[i] == 'factor'){
penguins = penguins %>%relocate(colnames(penguins)[i], .after = last_col())
}
}
for (i in 1:C){
if(type_column[i] == 'factor'){
penguins = penguins %>%relocate(colnames(penguins)[i], .after = last_col())
}
}
for (i in 1:C){
if(type_column[i] == 'factor'){
penguins = penguins %>%relocate(colnames(penguins)[i], .after = last_col())
}
}
for (i in 1:C){
if(type_column[i] == 'factor'){
penguins = penguins %>%relocate(colnames(penguins)[i], .after = last_col())
}
}
for (i in 1:C){
if(type_column[i] == 'factor'){
penguins = penguins %>%relocate(colnames(penguins)[i], .after = last_col())
}
}
for (i in 1:C){
if(type_column[i] == 'factor'){
penguins = penguins %>%relocate(colnames(penguins)[i], .after = last_col())
}
}
penguins
require(palmerpenguins)
penguins
penguins
install.packages('palmerpenguins')
install.packages("palmerpenguins")
penguins
knitr::opts_chunk$set(echo = TRUE)
require(palmerpenguins)
require(palmerpenguins)
penguins
require(palmerpenguins)
penguins
penguins %>% filter(bill_length_mm >= 48)
require(dplyr)
require(dplyr)
penguins %>% filter(bill_length_mm >= 48)
penguins %>%
filter(year != 2008, sex == 'male', species == 'Adelie')
for (i in 1:C){
if(type_column[i] == 'factor'){
penguins %>%relocate(colnames(penguins)[i], .after = last_col())
}
}
C = dim(penguins)[2]
type_column = sapply(penguins, class)
for (i in 1:C){
if(type_column[i] == 'factor'){
penguins %>%relocate(colnames(penguins)[i], .after = last_col())
}
}
penguins
for (i in 1:C){
if(type_column[i] == 'factor'){
relocate(.data = penguins, colnames(penguins)[i], .after = last_col())
}
}
penguins
penguins %>%
rename_with(toupper(starts_with('bill')), starts_with("bill"))
penguins %>%
rename_with('BILL', starts_with("bill"))
penguins %>%
rename_with(BILL, starts_with("bill"))
penguins %>%
rename_with('BILL', starts_with("bill"))
toupper('rte')
toupper('sgdfsgs')
starts_with("bill")
penguins %>% select(starts_with('bill'))
penguins %>% rename('BILL', starts_with('bill'))
penguins %>% rename(starts_with('bill'), toupper(starts_with('bill')))
penguins %>% rename(toupper(starts_with('bill')), starts_with('bill'))
penguins %>% rename(c('a','b'), starts_with('bill'))
penguins %>%
rename_with(toupper, starts_with("bill"))
penguins %>%
rename_with(toupper, starts_with("bill"))
penguins %>%
relocate(where(is.integer), where(is.factor))
penguins %>% rename(starts_with('bill'), toupper(starts_with('bill')asaf
penguins
penguins %>%
mutate(body_mass_k = body_mass_g /1000)
penguins %>%
mutate(body_mass_k = body_mass_g /1000) %>%
rename_with(tolower, island) %>%
rename_with(as.character, species)
penguins %>%
mutate(body_mass_k = body_mass_g /1000, species = as.character(species)) %>%
rename_with(tolower, island) %>%
penguins %>%
mutate(body_mass_k = body_mass_g /1000, species = as.character(species)) %>%
rename_with(tolower, island)
penguins %>%
mutate(body_mass_k = body_mass_g /1000, species = as.character(species)) %>%
rename_with(tolower, island)
penguins %>%
mutate(body_mass_k = body_mass_g /1000, species = as.character(species), island = rename_with(toupper, island))
penguins %>%
mutate(body_mass_k = body_mass_g /1000, species = as.character(species), island = tolower(island))
pinguins
penguins
chinstrap = penguins %>% filter(species == 'Chinstrap')
chinstrap
summary(chinstrap$flipper_length_mm)
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island) %>%
summary(chinstrap$flipper_length_mm)
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island) %>%
summarise(chinstrap$flipper_length_mm)
penguins
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island) %>%
summarise(max_len_flipper = max(flipper_length_mm), min_len_flipper = min(flipper_length_mm))
chinstrap
unique(penguins$species)
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island) %>%
#summarise(max_len_flipper = max(flipper_length_mm), min_len_flipper = min(flipper_length_mm))
chinstrap
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island)
chinstrap
unique(chinstrap$island)
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island)
summarise(max_len_flipper = max(flipper_length_mm), min_len_flipper = min(flipper_length_mm))
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island) %>%
summarise(max_len_flipper = max(flipper_length_mm), min_len_flipper = min(flipper_length_mm))
chinstrap
penguins %>%
group_by(species, year) %>%
summarize(
bill_depth_mean = mean(bill_depth_mm, na.rm = TRUE),
bill_length_mean = mean(bill_length_mm, na.rm = TRUE)
)
require(jsonlite)
bebidas = NULL
require(jsonlite)
bebidas = NULL
url_base = 'http://www.thecocktaildb.com/api/json/v1/1/search.php?f='
letra = 'a'
for(letra in letters){
print(paste('Letra:',letra))
dwld = fromJSON(paste(url_base,letra,sep=''))$drinks
bebidas = rbind(bebidas,dwld)
print(paste('Había',nrow(dwld),'bebidas'))
}
bebidas
dim(bebidas)
bebidas[1,grep('Ingredient',colnames(bebidas))]
sum(!is.na(bebidas[1,grep('Ingredient',colnames(bebidas))]))
length(grep('Ingredient',colnames(bebidas)))
cat(paste0(paste(bebidas$strDrink[1],bebidas[1,18:21],sep=','),collapse='\n'))
require(tidyverse)
print(paste('Empezamos con',nrow(bebidas),'filas'))
beb_tidy = bebidas %>%  # Al dataframe de bebidas
select(strDrink,strIngredient1:strIngredient15) %>% # Le seleccionamos los nombres de bebidas y sus ingredientes
group_by(strDrink) %>% #Avisamos que queremos agrupar las operaciones por bebida
unite('strIngredients',strIngredient1:strIngredient15,na.rm=TRUE,sep=',') #Unimos las columnas de ingredientes pegandolas con comas
print(paste('Ahora tenemos',nrow(beb_tidy),'filas y', ncol(beb_tidy),'columnas'))
print(paste('Empezamos con',nrow(bebidas),'filas'))
beb_tidy = bebidas %>%  # Al dataframe de bebidas
select(strDrink,strIngredient1:strIngredient15) %>% # Le seleccionamos los nombres de bebidas y sus ingredientes
group_by(strDrink) %>% #Avisamos que queremos agrupar las operaciones por bebida
unite('strIngredients',strIngredient1:strIngredient15,na.rm=TRUE,sep=',') #Unimos las columnas de ingredientes pegandolas con comas
print(paste('Ahora tenemos',nrow(beb_tidy),'filas y', ncol(beb_tidy),'columnas'))
beb_ejes = beb_tidy %>% # Al nuevo dataframe
separate_rows(strIngredients,sep=',') # Lo separamos en filas distintas por cada ingrediente
print(paste('Obtenemos finalmente',nrow(beb_ejes),'ejes'))
intersect(beb_ejes$strDrink,beb_ejes$strIngredients)
beb_tidy
beb_ejes = beb_tidy %>% # Al nuevo dataframe
separate_rows(strIngredients,sep=',') # Lo separamos en filas distintas por cada ingrediente
print(paste('Obtenemos finalmente',nrow(beb_ejes),'ejes'))
intersect(beb_ejes$strDrink,beb_ejes$strIngredients)
beb_ejes = beb_ejes %>% # Al dataset de ejes
mutate(strDrink = toupper(strDrink),strIngredients=tolower(strIngredients))  # Cambiamos la columna strDrink a mayúscula y strIngredients a minúscula
intersect(beb_ejes$strDrink,beb_ejes$strIngredients)
beb_ejes = beb_ejes %>% # Al dataset de ejes
mutate(strDrink = toupper(strDrink),strIngredients=tolower(strIngredients))  # Cambiamos la columna strDrink a mayúscula y strIngredients a minúscula
intersect(beb_ejes$strDrink,beb_ejes$strIngredients)
beb_ejes = beb_ejes %>% # Al dataset de ejes
mutate(strDrink = toupper(strDrink),strIngredients=tolower(strIngredients))  # Cambiamos la columna strDrink a mayúscula y strIngredients a minúscula
intersect(beb_ejes$strDrink,beb_ejes$strIngredients)
beb_ejes %>%
count(strDrink,name='nIngredients') %>% # Contamos cuantas veces aparece cada bebida, ese es su total de ingredientes
arrange(desc(nIngredients)) # Lo ordenamos en orden descendente
beb_ejes %>% # Lo mismo pero en orden ascendente
count(strDrink,name='nIngredients') %>%
arrange(nIngredients)
beb_ejes %>%
count(strDrink,name='nIngredients') %>% # Contamos ingredientes
ungroup() %>% #Desagrupamos para hacer sumarios
summarise(media=mean(nIngredients),stdev=sd(nIngredients),min=min(nIngredients),max=max(nIngredients)) # Calculamos algunas medidas
beb_ejes %>% # Hacemos un histograma de la cantidad de apariciones de cada ingrediente
count(strDrink,name='nIngredients') %>%
ggplot(mapping=aes(x=nIngredients)) +
geom_histogram(binwidth = 1,fill='white',col='black') +
geom_boxplot(width=10,color='blue',lwd=1.5)
# Si aún no los instalaron:
install.packages('igraph')
# Si aún no los instalaron:
install.packages('igraph')
install.packages('tidygraph')
require(igraph)
require(tidygraph)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
### Ejercicios
##### 1 Datos del experimento de visualización
En la [clase de visualización](https://youtu.be/Pc3vxs2ZPAE?t=870) participaron de un
[experimento](https://forms.gle/B5FpDJGTp1i8d4E87). Una de las preguntas era cuál es
el área del círculo pequeño respecto del más grande en esta figura:
![](circ.png){width=20% height=20%}
La respuesta correcta era 75%. La otra pregunta relevante era a qué altura está el punto de
abajo, entre 0 y 100, en la siguiente figura:
![](puntos.png){width=20% height=20%}
Las respuestas de ustedes están en [esta planilla](https://docs.google.com/spreadsheets/d/1LrA-7-dJnJaKrLKTPm2eykVdebvPeLiBRKvIYALQY60/edit?usp=sharing).
Lo primero que tienen que hacer es bajar los datos en un csv y luego leerlos en R
con la función `read_csv()` de `tidyverse`.
Los datos no están en formato tidy, así que no están preparados para usarse ¿Por qué?
Antes de hacer nada, piensen cómo tendrían que verse los datos para que estén en
formato tidy.
Usar la función `pivot_longer()` para transformar los datos a un formato tidy. Llamar
al nuevo dataset `data.tidy`.
```{r eval=F, echo=T, message=FALSE, warning=FALSE}
d <- read_csv("DATOS_EXP_DATOS.csv")
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (), names_to = _____, values_to = _____)
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (), names_to = _____, values_to = _____)
d <- read_csv("DATOS_EXP_DATOS.csv")
d
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (1:2), names_to = 'numero', values_to = 'geometria')
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (1:2), names_to = 'numero', values_to = 'geometria')
d.tidy
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (2:3
), names_to = 'numero', values_to = 'geometria')
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (2:3), names_to = 'numero', values_to = 'geometria')
d.tidy
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (2:3), names_to = 'geometria', values_to = 'numero')
d.tidy
d <- read_csv("/Users/gsolovey/Downloads/data_exp.csv")
d <- read_csv("DATOS_EXP_DATOS.csv")
colnames(d) <- c("circulos","puntos")
d.tidy <- d %>% pivot_longer(cols = c(circulos, puntos), names_to = "preg", values_to = "porc")
d <- read_csv("DATOS_EXP_DATOS.csv")
colnames(d) <- c("circulos","puntos")
d.tidy <- d %>% pivot_longer(cols = c(circulos, puntos), names_to = "preg", values_to = "porc")
d
colnames(d) <- c("id","circulos","puntos")
d.tidy <- d %>% pivot_longer(cols = c(circulos, puntos), names_to = "preg", values_to = "porc")
ggplot(data = d.tidy, aes(x = preg,
y = porc,
color = preg)) +
geom_violin(fill = "gray80", size = 1, alpha = .5) +
geom_dotplot(binaxis='y', stackdir='center', dotsize = 1.2, binwidth = 1) +
geom_boxplot(outlier.alpha = 0, alpha = 0.4, coef = 0, width = .05) +
geom_hline(yintercept=75, color = "gray10") +
coord_flip() +
theme_minimal() +
labs(x = "",
y = "respuesta (%)",
color = "",
title = "Rta. correcta = 75%") +
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 0, size = 15),
axis.text.x = element_text(vjust = 0, size = 15),
axis.text.y = element_text(vjust = 0, size = 15),
legend.position = "none")
install.packages("gapminder")
library(gapminder)
require(tidyverse)
require(gapminder)
gapminder %>%
group_by(country) %>%
filter(year == 2007) %>%
mutate(pop.inmillions = pop / 1000000) %>%
ggplot(mapping = aes(x = gdpPercap,
y = lifeExp,
color = continent,
size = pop.inmillions)) +
geom_point() +
scale_x_continuous(trans = 'log10') +
labs(x = "PBI per cápita",
y = "Expectativa de vida (años)",
color = "Continente",
size = "Pob. en millones",
title = "Año 2007 (Fuente: Gapminder)") +
theme_minimal()
install.packages("lubridate")
install.packages("lubridate")
library(lubridate)
knitr::opts_chunk$set(echo = TRUE)
install.packages("lubridate")
library(lubridate)
install.packages("lubridate")
install.packages("lubridate")
knitr::opts_chunk$set(echo = TRUE)
library(lubridate)
install.packages("lubridate")
install.packages("lubridate")
knitr::opts_chunk$set(echo = TRUE)
library(lubridate)
require(lubridate)
d.temp <- read_csv("/Users/gsolovey/Dropbox/work/2021/cursos/laboratorio de datos/TP1/historico_temperaturas.csv")
d.temp <- read_csv("../historico_temperaturas.csv")
d.temp <- read_csv("./historico_temperaturas.csv")
d.temp <- read_csv("data/historico_temperaturas.csv")
d.temp <- read_csv("../data/historico_temperaturas.csv")
d.temp <- read_csv("./data/historico_temperaturas.csv")
d.temp <- read_csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("../tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("../Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("/home/tomi/Tomi/laboDeDatos/data")
d.temp <- read_csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
require(lubridate)
d.temp <- read_csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read.csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read.csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d <- d.temp %>%
mutate( mes.num = case_when( mes == "Enero" ~ 1,
mes == "Febrero" ~ 2,
mes == "Marzo" ~ 3,
mes == "Abril" ~ 4,
mes == "Mayo" ~ 5,
mes == "Junio" ~ 6,
mes == "Julio" ~ 7,
mes == "Agosto" ~ 8,
mes == "Septiembre" ~ 9,
mes == "Octubre" ~ 10,
mes == "Noviembre" ~ 11,
mes == "Diciembre" ~ 12))  %>%
mutate(fecha = make_date(year = año, month = as.double(mes.num))) %>%
filter( año < 2020)
require(tidyverse)
d <- d.temp %>%
mutate( mes.num = case_when( mes == "Enero" ~ 1,
mes == "Febrero" ~ 2,
mes == "Marzo" ~ 3,
mes == "Abril" ~ 4,
mes == "Mayo" ~ 5,
mes == "Junio" ~ 6,
mes == "Julio" ~ 7,
mes == "Agosto" ~ 8,
mes == "Septiembre" ~ 9,
mes == "Octubre" ~ 10,
mes == "Noviembre" ~ 11,
mes == "Diciembre" ~ 12))  %>%
mutate(fecha = make_date(year = año, month = as.double(mes.num))) %>%
filter( año < 2020)
ggplot(data = d, mapping = aes(x = fecha, y = media, color = media)) +
geom_point() +
geom_line(mapping = aes(y = mínima)) +
geom_line(mapping = aes(y = máxima)) +
labs(x = "", y = "Temperatura media (°C)", color = "T (°C)") +
theme_classic() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8),
axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)),
plot.margin=unit(c(1,1,1.5,1.2),"cm"),
strip.text = element_text(face = "bold", color = "black", hjust = 0, size = 8),
strip.background = element_rect(fill = "gray90", color = "gray")) +
facet_wrap(~ año, scales = "free_x") +
scale_color_viridis_c(option = "plasma")
d
filter( año != 2020 )
# usar mutate() y case_when para crear una nueva variable que contenga
# el número del mes.
# a esa nueva variable llamarla mes.num
# luego con la función make_date, crear la variable fecha
# por último eliminar los datos del año 2020 porque están incompletos.
d <- d.temp %>%
# usar mutate() y case_when para crear una nueva variable que contenga
# el número del mes.
# a esa nueva variable llamarla mes.num
# luego con la función make_date, crear la variable fecha
# por último eliminar los datos del año 2020 porque están incompletos.
d <- d.temp %>%
d <- d.temp %>%
mutate( mes.num = case_when( mes == "Enero" ~ 1,
mes == "Febrero" ~ 2,
mes == "Marzo" ~ 3,
mes == "Abril" ~ 4,
mes == "Mayo" ~ 5,
mes == "Junio" ~ 6,
mes == "Julio" ~ 7,
mes == "Agosto" ~ 8,
mes == "Septiembre" ~ 9,
mes == "Octubre" ~ 10,
mes == "Noviembre" ~ 11,
mes == "Diciembre" ~ 12)) %>%
mutate(fecha = make_date(year = año, month = as.double(mes.num)) %>%
filter( año != 2020 )
d
d
d
df_2019 = read.csv('../Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('./Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('C:/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('./Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('./Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('../Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('./Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
setwd("~/Tomi/laboDeDatos/TP_LaboDeDatos")
df_2019 = read.csv('Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('./Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('./Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
df_2019 = read.csv('../Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
df_2019 = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
df_2019 = read.csv('Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
d <- read_csv("DATOS_EXP_DATOS.csv")
d <- read.csv("DATOS_EXP_DATOS.csv")
datos = read.csv('./data/historico_temperaturas.csv')
View(datos)
datos = read.csv('./data/historico_temperaturas.csv')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv')
datos = read.csv('home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
datos = read.csv('home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'latin-1')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'latin1')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'utf-8')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'UTF-8')
latin1
datos = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'latin1')
datos = read.csv('../TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'latin1')
datos_2019 = read.csv('../TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'latin1')
View(datos_2019)
datos_2019 = read.csv('../TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'latin1', sep = ';')
View(datos_2019)
#library(RCurl)
#myfile <- getURL('https://sakai.unc.edu/access/content/group/3d1eb92e-7848-4f55-90c3-7c72a54e7e43/public/data/bycatch.csv', #ssl.verifyhost=FALSE, ssl.verifypeer=FALSE)
datos_2014 = read.csv('../TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2014.csv', encoding = 'latin1', sep = ';')
#library(RCurl)
#myfile <- getURL('https://sakai.unc.edu/access/content/group/3d1eb92e-7848-4f55-90c3-7c72a54e7e43/public/data/bycatch.csv', #ssl.verifyhost=FALSE, ssl.verifypeer=FALSE)
datos_2014 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2014.csv', encoding = 'latin1', sep = ';')
#library(RCurl)
#myfile <- getURL('https://sakai.unc.edu/access/content/group/3d1eb92e-7848-4f55-90c3-7c72a54e7e43/public/data/bycatch.csv', #ssl.verifyhost=FALSE, ssl.verifypeer=FALSE)
datos_2014 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2014.csv', encoding = 'latin1', sep = ';')
datos_2015 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2015.csv', encoding = 'latin1', sep = ';')
datos_2016 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2016.csv', encoding = 'latin1', sep = ';')
datos_2017 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2017.csv', encoding = 'latin1', sep = ';')
datos_2017 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2017.csv', encoding = 'latin1', sep = ';')
datos_2018 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2018.csv', encoding = 'latin1', sep = ';')
datos_2019 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv', encoding = 'latin1', sep = ';')
datos_2020 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2020.csv', encoding = 'latin1', sep = ';')
# Librerias
require(tidyverse)
install.packages(geosphere)
install.packages('geosphere')
require(geosphere)
require(geosphere)
View(datos_2016)
