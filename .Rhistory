rename_with(tolower, island)
penguins %>%
mutate(body_mass_k = body_mass_g /1000, species = as.character(species), island = rename_with(toupper, island))
penguins %>%
mutate(body_mass_k = body_mass_g /1000, species = as.character(species), island = tolower(island))
pinguins
penguins
chinstrap = penguins %>% filter(species == 'Chinstrap')
chinstrap
summary(chinstrap$flipper_length_mm)
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island) %>%
summary(chinstrap$flipper_length_mm)
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island) %>%
summarise(chinstrap$flipper_length_mm)
penguins
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island) %>%
summarise(max_len_flipper = max(flipper_length_mm), min_len_flipper = min(flipper_length_mm))
chinstrap
unique(penguins$species)
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island) %>%
#summarise(max_len_flipper = max(flipper_length_mm), min_len_flipper = min(flipper_length_mm))
chinstrap
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island)
chinstrap
unique(chinstrap$island)
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island)
summarise(max_len_flipper = max(flipper_length_mm), min_len_flipper = min(flipper_length_mm))
chinstrap = penguins %>%
filter(species == 'Chinstrap') %>%
group_by(island) %>%
summarise(max_len_flipper = max(flipper_length_mm), min_len_flipper = min(flipper_length_mm))
chinstrap
penguins %>%
group_by(species, year) %>%
summarize(
bill_depth_mean = mean(bill_depth_mm, na.rm = TRUE),
bill_length_mean = mean(bill_length_mm, na.rm = TRUE)
)
require(jsonlite)
bebidas = NULL
require(jsonlite)
bebidas = NULL
url_base = 'http://www.thecocktaildb.com/api/json/v1/1/search.php?f='
letra = 'a'
for(letra in letters){
print(paste('Letra:',letra))
dwld = fromJSON(paste(url_base,letra,sep=''))$drinks
bebidas = rbind(bebidas,dwld)
print(paste('Había',nrow(dwld),'bebidas'))
}
bebidas
dim(bebidas)
bebidas[1,grep('Ingredient',colnames(bebidas))]
sum(!is.na(bebidas[1,grep('Ingredient',colnames(bebidas))]))
length(grep('Ingredient',colnames(bebidas)))
cat(paste0(paste(bebidas$strDrink[1],bebidas[1,18:21],sep=','),collapse='\n'))
require(tidyverse)
print(paste('Empezamos con',nrow(bebidas),'filas'))
beb_tidy = bebidas %>%  # Al dataframe de bebidas
select(strDrink,strIngredient1:strIngredient15) %>% # Le seleccionamos los nombres de bebidas y sus ingredientes
group_by(strDrink) %>% #Avisamos que queremos agrupar las operaciones por bebida
unite('strIngredients',strIngredient1:strIngredient15,na.rm=TRUE,sep=',') #Unimos las columnas de ingredientes pegandolas con comas
print(paste('Ahora tenemos',nrow(beb_tidy),'filas y', ncol(beb_tidy),'columnas'))
print(paste('Empezamos con',nrow(bebidas),'filas'))
beb_tidy = bebidas %>%  # Al dataframe de bebidas
select(strDrink,strIngredient1:strIngredient15) %>% # Le seleccionamos los nombres de bebidas y sus ingredientes
group_by(strDrink) %>% #Avisamos que queremos agrupar las operaciones por bebida
unite('strIngredients',strIngredient1:strIngredient15,na.rm=TRUE,sep=',') #Unimos las columnas de ingredientes pegandolas con comas
print(paste('Ahora tenemos',nrow(beb_tidy),'filas y', ncol(beb_tidy),'columnas'))
beb_ejes = beb_tidy %>% # Al nuevo dataframe
separate_rows(strIngredients,sep=',') # Lo separamos en filas distintas por cada ingrediente
print(paste('Obtenemos finalmente',nrow(beb_ejes),'ejes'))
intersect(beb_ejes$strDrink,beb_ejes$strIngredients)
beb_tidy
beb_ejes = beb_tidy %>% # Al nuevo dataframe
separate_rows(strIngredients,sep=',') # Lo separamos en filas distintas por cada ingrediente
print(paste('Obtenemos finalmente',nrow(beb_ejes),'ejes'))
intersect(beb_ejes$strDrink,beb_ejes$strIngredients)
beb_ejes = beb_ejes %>% # Al dataset de ejes
mutate(strDrink = toupper(strDrink),strIngredients=tolower(strIngredients))  # Cambiamos la columna strDrink a mayúscula y strIngredients a minúscula
intersect(beb_ejes$strDrink,beb_ejes$strIngredients)
beb_ejes = beb_ejes %>% # Al dataset de ejes
mutate(strDrink = toupper(strDrink),strIngredients=tolower(strIngredients))  # Cambiamos la columna strDrink a mayúscula y strIngredients a minúscula
intersect(beb_ejes$strDrink,beb_ejes$strIngredients)
beb_ejes = beb_ejes %>% # Al dataset de ejes
mutate(strDrink = toupper(strDrink),strIngredients=tolower(strIngredients))  # Cambiamos la columna strDrink a mayúscula y strIngredients a minúscula
intersect(beb_ejes$strDrink,beb_ejes$strIngredients)
beb_ejes %>%
count(strDrink,name='nIngredients') %>% # Contamos cuantas veces aparece cada bebida, ese es su total de ingredientes
arrange(desc(nIngredients)) # Lo ordenamos en orden descendente
beb_ejes %>% # Lo mismo pero en orden ascendente
count(strDrink,name='nIngredients') %>%
arrange(nIngredients)
beb_ejes %>%
count(strDrink,name='nIngredients') %>% # Contamos ingredientes
ungroup() %>% #Desagrupamos para hacer sumarios
summarise(media=mean(nIngredients),stdev=sd(nIngredients),min=min(nIngredients),max=max(nIngredients)) # Calculamos algunas medidas
beb_ejes %>% # Hacemos un histograma de la cantidad de apariciones de cada ingrediente
count(strDrink,name='nIngredients') %>%
ggplot(mapping=aes(x=nIngredients)) +
geom_histogram(binwidth = 1,fill='white',col='black') +
geom_boxplot(width=10,color='blue',lwd=1.5)
# Si aún no los instalaron:
install.packages('igraph')
# Si aún no los instalaron:
install.packages('igraph')
install.packages('tidygraph')
require(igraph)
require(tidygraph)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
### Ejercicios
##### 1 Datos del experimento de visualización
En la [clase de visualización](https://youtu.be/Pc3vxs2ZPAE?t=870) participaron de un
[experimento](https://forms.gle/B5FpDJGTp1i8d4E87). Una de las preguntas era cuál es
el área del círculo pequeño respecto del más grande en esta figura:
![](circ.png){width=20% height=20%}
La respuesta correcta era 75%. La otra pregunta relevante era a qué altura está el punto de
abajo, entre 0 y 100, en la siguiente figura:
![](puntos.png){width=20% height=20%}
Las respuestas de ustedes están en [esta planilla](https://docs.google.com/spreadsheets/d/1LrA-7-dJnJaKrLKTPm2eykVdebvPeLiBRKvIYALQY60/edit?usp=sharing).
Lo primero que tienen que hacer es bajar los datos en un csv y luego leerlos en R
con la función `read_csv()` de `tidyverse`.
Los datos no están en formato tidy, así que no están preparados para usarse ¿Por qué?
Antes de hacer nada, piensen cómo tendrían que verse los datos para que estén en
formato tidy.
Usar la función `pivot_longer()` para transformar los datos a un formato tidy. Llamar
al nuevo dataset `data.tidy`.
```{r eval=F, echo=T, message=FALSE, warning=FALSE}
d <- read_csv("DATOS_EXP_DATOS.csv")
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (), names_to = _____, values_to = _____)
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (), names_to = _____, values_to = _____)
d <- read_csv("DATOS_EXP_DATOS.csv")
d
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (1:2), names_to = 'numero', values_to = 'geometria')
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (1:2), names_to = 'numero', values_to = 'geometria')
d.tidy
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (2:3
), names_to = 'numero', values_to = 'geometria')
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (2:3), names_to = 'numero', values_to = 'geometria')
d.tidy
# tienen nombres las variables? si no tienen, pongan un nombre a cada una, tipo
# circulos y puntos.
d.tidy <- d %>% pivot_longer(cols = (2:3), names_to = 'geometria', values_to = 'numero')
d.tidy
d <- read_csv("/Users/gsolovey/Downloads/data_exp.csv")
d <- read_csv("DATOS_EXP_DATOS.csv")
colnames(d) <- c("circulos","puntos")
d.tidy <- d %>% pivot_longer(cols = c(circulos, puntos), names_to = "preg", values_to = "porc")
d <- read_csv("DATOS_EXP_DATOS.csv")
colnames(d) <- c("circulos","puntos")
d.tidy <- d %>% pivot_longer(cols = c(circulos, puntos), names_to = "preg", values_to = "porc")
d
colnames(d) <- c("id","circulos","puntos")
d.tidy <- d %>% pivot_longer(cols = c(circulos, puntos), names_to = "preg", values_to = "porc")
ggplot(data = d.tidy, aes(x = preg,
y = porc,
color = preg)) +
geom_violin(fill = "gray80", size = 1, alpha = .5) +
geom_dotplot(binaxis='y', stackdir='center', dotsize = 1.2, binwidth = 1) +
geom_boxplot(outlier.alpha = 0, alpha = 0.4, coef = 0, width = .05) +
geom_hline(yintercept=75, color = "gray10") +
coord_flip() +
theme_minimal() +
labs(x = "",
y = "respuesta (%)",
color = "",
title = "Rta. correcta = 75%") +
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 0, size = 15),
axis.text.x = element_text(vjust = 0, size = 15),
axis.text.y = element_text(vjust = 0, size = 15),
legend.position = "none")
install.packages("gapminder")
library(gapminder)
require(tidyverse)
require(gapminder)
gapminder %>%
group_by(country) %>%
filter(year == 2007) %>%
mutate(pop.inmillions = pop / 1000000) %>%
ggplot(mapping = aes(x = gdpPercap,
y = lifeExp,
color = continent,
size = pop.inmillions)) +
geom_point() +
scale_x_continuous(trans = 'log10') +
labs(x = "PBI per cápita",
y = "Expectativa de vida (años)",
color = "Continente",
size = "Pob. en millones",
title = "Año 2007 (Fuente: Gapminder)") +
theme_minimal()
install.packages("lubridate")
install.packages("lubridate")
library(lubridate)
knitr::opts_chunk$set(echo = TRUE)
install.packages("lubridate")
library(lubridate)
install.packages("lubridate")
install.packages("lubridate")
knitr::opts_chunk$set(echo = TRUE)
library(lubridate)
install.packages("lubridate")
install.packages("lubridate")
knitr::opts_chunk$set(echo = TRUE)
library(lubridate)
require(lubridate)
d.temp <- read_csv("/Users/gsolovey/Dropbox/work/2021/cursos/laboratorio de datos/TP1/historico_temperaturas.csv")
d.temp <- read_csv("../historico_temperaturas.csv")
d.temp <- read_csv("./historico_temperaturas.csv")
d.temp <- read_csv("data/historico_temperaturas.csv")
d.temp <- read_csv("../data/historico_temperaturas.csv")
d.temp <- read_csv("./data/historico_temperaturas.csv")
d.temp <- read_csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("../tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("../Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("/home/tomi/Tomi/laboDeDatos/data")
d.temp <- read_csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
require(lubridate)
d.temp <- read_csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read_csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read.csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d.temp <- read.csv("/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv")
d <- d.temp %>%
mutate( mes.num = case_when( mes == "Enero" ~ 1,
mes == "Febrero" ~ 2,
mes == "Marzo" ~ 3,
mes == "Abril" ~ 4,
mes == "Mayo" ~ 5,
mes == "Junio" ~ 6,
mes == "Julio" ~ 7,
mes == "Agosto" ~ 8,
mes == "Septiembre" ~ 9,
mes == "Octubre" ~ 10,
mes == "Noviembre" ~ 11,
mes == "Diciembre" ~ 12))  %>%
mutate(fecha = make_date(year = año, month = as.double(mes.num))) %>%
filter( año < 2020)
require(tidyverse)
d <- d.temp %>%
mutate( mes.num = case_when( mes == "Enero" ~ 1,
mes == "Febrero" ~ 2,
mes == "Marzo" ~ 3,
mes == "Abril" ~ 4,
mes == "Mayo" ~ 5,
mes == "Junio" ~ 6,
mes == "Julio" ~ 7,
mes == "Agosto" ~ 8,
mes == "Septiembre" ~ 9,
mes == "Octubre" ~ 10,
mes == "Noviembre" ~ 11,
mes == "Diciembre" ~ 12))  %>%
mutate(fecha = make_date(year = año, month = as.double(mes.num))) %>%
filter( año < 2020)
ggplot(data = d, mapping = aes(x = fecha, y = media, color = media)) +
geom_point() +
geom_line(mapping = aes(y = mínima)) +
geom_line(mapping = aes(y = máxima)) +
labs(x = "", y = "Temperatura media (°C)", color = "T (°C)") +
theme_classic() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, size = 8),
axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)),
plot.margin=unit(c(1,1,1.5,1.2),"cm"),
strip.text = element_text(face = "bold", color = "black", hjust = 0, size = 8),
strip.background = element_rect(fill = "gray90", color = "gray")) +
facet_wrap(~ año, scales = "free_x") +
scale_color_viridis_c(option = "plasma")
d
filter( año != 2020 )
# usar mutate() y case_when para crear una nueva variable que contenga
# el número del mes.
# a esa nueva variable llamarla mes.num
# luego con la función make_date, crear la variable fecha
# por último eliminar los datos del año 2020 porque están incompletos.
d <- d.temp %>%
# usar mutate() y case_when para crear una nueva variable que contenga
# el número del mes.
# a esa nueva variable llamarla mes.num
# luego con la función make_date, crear la variable fecha
# por último eliminar los datos del año 2020 porque están incompletos.
d <- d.temp %>%
d <- d.temp %>%
mutate( mes.num = case_when( mes == "Enero" ~ 1,
mes == "Febrero" ~ 2,
mes == "Marzo" ~ 3,
mes == "Abril" ~ 4,
mes == "Mayo" ~ 5,
mes == "Junio" ~ 6,
mes == "Julio" ~ 7,
mes == "Agosto" ~ 8,
mes == "Septiembre" ~ 9,
mes == "Octubre" ~ 10,
mes == "Noviembre" ~ 11,
mes == "Diciembre" ~ 12)) %>%
mutate(fecha = make_date(year = año, month = as.double(mes.num)) %>%
filter( año != 2020 )
d
d
d
df_2019 = read.csv('../Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('./Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('C:/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('./Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('./Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('../Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('./Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
setwd("~/Tomi/laboDeDatos/TP_LaboDeDatos")
df_2019 = read.csv('Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('./Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv')
df_2019 = read.csv('./Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
df_2019 = read.csv('../Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
df_2019 = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
df_2019 = read.csv('Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
d <- read_csv("DATOS_EXP_DATOS.csv")
d <- read.csv("DATOS_EXP_DATOS.csv")
datos = read.csv('./data/historico_temperaturas.csv')
View(datos)
datos = read.csv('./data/historico_temperaturas.csv')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/data/historico_temperaturas.csv')
datos = read.csv('home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
datos = read.csv('home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'latin-1')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'latin1')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'utf-8')
datos = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'UTF-8')
latin1
datos = read.csv('/home/tomi/Tomi/laboDeDatos/TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'latin1')
datos = read.csv('../TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'latin1')
datos_2019 = read.csv('../TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'latin1')
View(datos_2019)
datos_2019 = read.csv('../TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2019.csv', encoding = 'latin1', sep = ';')
View(datos_2019)
#library(RCurl)
#myfile <- getURL('https://sakai.unc.edu/access/content/group/3d1eb92e-7848-4f55-90c3-7c72a54e7e43/public/data/bycatch.csv', #ssl.verifyhost=FALSE, ssl.verifypeer=FALSE)
datos_2014 = read.csv('../TP_LaboDeDatos/Data/aterrizajes_y_despegues_registrados_por_eana_2014.csv', encoding = 'latin1', sep = ';')
#library(RCurl)
#myfile <- getURL('https://sakai.unc.edu/access/content/group/3d1eb92e-7848-4f55-90c3-7c72a54e7e43/public/data/bycatch.csv', #ssl.verifyhost=FALSE, ssl.verifypeer=FALSE)
datos_2014 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2014.csv', encoding = 'latin1', sep = ';')
#library(RCurl)
#myfile <- getURL('https://sakai.unc.edu/access/content/group/3d1eb92e-7848-4f55-90c3-7c72a54e7e43/public/data/bycatch.csv', #ssl.verifyhost=FALSE, ssl.verifypeer=FALSE)
datos_2014 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2014.csv', encoding = 'latin1', sep = ';')
datos_2015 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2015.csv', encoding = 'latin1', sep = ';')
datos_2016 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2016.csv', encoding = 'latin1', sep = ';')
datos_2017 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2017.csv', encoding = 'latin1', sep = ';')
datos_2017 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2017.csv', encoding = 'latin1', sep = ';')
datos_2018 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2018.csv', encoding = 'latin1', sep = ';')
datos_2019 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv', encoding = 'latin1', sep = ';')
datos_2020 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2020.csv', encoding = 'latin1', sep = ';')
# Librerias
require(tidyverse)
install.packages(geosphere)
install.packages('geosphere')
require(geosphere)
require(geosphere)
View(datos_2016)
# Llamamos a los DataSets
datos_2014 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2014.csv', encoding = 'latin1', sep = ';')
datos_2015 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2015.csv', encoding = 'latin1', sep = ';')
datos_2016 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2016.csv', encoding = 'latin1', sep = ';')
datos_2017 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2017.csv', encoding = 'latin1', sep = ';')
datos_2018 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2018.csv', encoding = 'latin1', sep = ';')
datos_2019 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv', encoding = 'latin1', sep = ';')
datos_2020 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2020.csv', encoding = 'latin1', sep = ';')
# Concateno todos los datos
datos = rbind(datos_2014,datos_2015,datos_2016,datos_2017,datos_2018,datos_2019,datos_2020)
datos2= read.csv('../TP_LaboDeDatos/Data/202109-informe-ministerio.csv', encoding = 'latin1', sep = ';')
# Librerias
require(tidyverse)
require(geosphere)
require(rvest) # Cargamos el paquete
# Llamamos a los DataSets
datos_2014 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2014.csv', encoding = 'latin1', sep = ';')
datos_2015 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2015.csv', encoding = 'latin1', sep = ';')
datos_2016 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2016.csv', encoding = 'latin1', sep = ';')
datos_2017 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2017.csv', encoding = 'latin1', sep = ';')
datos_2018 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2018.csv', encoding = 'latin1', sep = ';')
datos_2019 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2019.csv', encoding = 'latin1', sep = ';')
datos_2020 = read.csv('../TP_LaboDeDatos/Data/aterrizajes-y-despegues-registrados-por-eana-2020.csv', encoding = 'latin1', sep = ';')
# Concateno todos los datos
datos = rbind(datos_2014,datos_2015,datos_2016,datos_2017,datos_2018,datos_2019,datos_2020)
datos2= read.csv('../TP_LaboDeDatos/Data/202109-informe-ministerio.csv', encoding = 'latin1', sep = ';')
View(datos2)
View(datos2)
# Utilizamos la tabla que se encuentra en 'https://en.wikipedia.org/wiki/List_of_airports_in_Argentina'
# para acceder a las variables de ciudad, provincia y coordenadas de cada aeropuerto
aeropuertos_wiki = read_html('https://en.wikipedia.org/wiki/List_of_airports_in_Argentina')
elemento_tabla   = html_element(aeropuertos_wiki,'.wikitable')
aeropuertos      = html_table(elemento_tabla)
# Variables utiles
N = dim(datos)[1]
cant_aeropuertos = dim(aeropuertos)[1]
# Corrijo la columna de coordenadas
separar     = strsplit((aeropuertos$Coordinates), '/') # Divide a los strings en los lugares donde haya '/'
coordenadas = sapply(separar, function(x) x[3])        # Me quedo solo con el 3er tipo de coordenada
coordenadas = gsub('[^0-9,.,-]','', coordenadas)           # Elimino los caracteres que no quiero utilizar
aeropuertos = aeropuertos %>%
mutate(lat = as.numeric(substr(coordenadas, 1, 9)), long = as.numeric(substr(coordenadas, 10, 18))) # Separo a mano latitud y longitud (revizar si esta todo en orden)
aeropuertos = filter(aeropuertos, nchar(ICAO)>1)
aeropuertos = aeropuertos[order(aeropuertos$ICAO),]
#Por ahora esta parte no sirve pero está bueno tenerla
# Agregando Ciudades
N2 = length(datos2$Hora.UTC)
datos2$ciudad_origen     = rep(NA, length(N2))
datos2$ciudad_destino    = rep(NA, length(N2))
datos2$provincia_origen  = rep(NA, length(N2))
datos2$provincia_destino = rep(NA, length(N2))
datos2$lat_origen        = rep(NA, length(N2))
datos2$long_origen       = rep(NA, length(N2))
datos2$lat_destino       = rep(NA, length(N2))
datos2$long_destino      = rep(NA, length(N2))
# datos %>% mutate(ciudad_origen = ) # Aca queria hacer exactamente lo de arriba pero usando dplyr
# El algoritmo de abajo ndar anda, tarda un monton. Hay que agregar el resto de las variables
for(i in 1:length(aeropuertos$ICAO)){
inds = datos$Origen.OACI==aeropuertos$ICAO[i]
datos2[inds,c('ciudad_origen','provincia_origen','lat_origen','long_origen')] = aeropuertos[i,c("City served","Province","lat","long")]
inds = datos2$Origen==aeropuertos$IATA[i]
datos2[inds,c('ciudad_destino','provincia_destino','lat_destino','long_destino')] = aeropuertos[i,c("City served","Province","lat","long")]
}
#Por ahora esta parte no sirve pero está bueno tenerla
# Agregando Ciudades
N2 = length(datos2$Hora.UTC)
datos2$ciudad_origen     = rep(NA, length(N2))
datos2$ciudad_destino    = rep(NA, length(N2))
datos2$provincia_origen  = rep(NA, length(N2))
datos2$provincia_destino = rep(NA, length(N2))
datos2$lat_origen        = rep(NA, length(N2))
datos2$long_origen       = rep(NA, length(N2))
datos2$lat_destino       = rep(NA, length(N2))
datos2$long_destino      = rep(NA, length(N2))
# datos %>% mutate(ciudad_origen = ) # Aca queria hacer exactamente lo de arriba pero usando dplyr
# El algoritmo de abajo ndar anda, tarda un monton. Hay que agregar el resto de las variables
for(i in 1:length(aeropuertos$ICAO)){
inds = datos2$Aeropuerto==aeropuertos$IATA[i]
datos2[inds,c('ciudad_origen','provincia_origen','lat_origen','long_origen')] = aeropuertos[i,c("City served","Province","lat","long")]
inds = datos2$Origen...Destino==aeropuertos$IATA[i]
datos2[inds,c('ciudad_destino','provincia_destino','lat_destino','long_destino')] = aeropuertos[i,c("City served","Province","lat","long")]
}
View(datos2)
View(datos2)
datos2 = drop_na(datos2)
print(length(datos2))
print(length(datos2$Fecha))
datos2$distancia = distHaversine(c(datos2$long_origen,datos2$lat_origen),c(datos2$long_destino,datos2$lat_destino))
datos2$distancia = distHaversine(datos2[c("long_origen","lat_origen"),],datos2[c("long_origen","lat_origen"),])
datos2[c("long_origen","lat_origen"),]
datos2[,c("long_origen","lat_origen")]
datos2$distancia = distHaversine(datos2[,c("long_origen","lat_origen")],datos2[,c("long_origen","lat_origen")])
datos2$distancia = distHaversine(datos2[,c("long_origen","lat_origen")],datos2[,c("long_destino","lat_destino")])
datos$distancia = distHaversine(datos[,c("long_origen","lat_origen")],datos[,c("long_destino","lat_destino")])
#Por ahora esta parte no sirve pero está bueno tenerla
# Agregando Ciudades
datos$ciudad_origen     = rep(NA, length(N))
datos$ciudad_destino    = rep(NA, length(N))
datos$provincia_origen  = rep(NA, length(N))
datos$provincia_destino = rep(NA, length(N))
datos$lat_origen        = rep(NA, length(N))
datos$long_origen       = rep(NA, length(N))
datos$lat_destino       = rep(NA, length(N))
datos$long_destino      = rep(NA, length(N))
# datos %>% mutate(ciudad_origen = ) # Aca queria hacer exactamente lo de arriba pero usando dplyr
# El algoritmo de abajo ndar anda, tarda un monton. Hay que agregar el resto de las variables
for(i in 1:length(aeropuertos$ICAO)){
inds = datos$Origen.OACI==aeropuertos$ICAO[i]
datos[inds,c('ciudad_origen','provincia_origen','lat_origen','long_origen')] = aeropuertos[i,c("City served","Province","lat","long")]
inds = datos$Origen.OACI==aeropuertos$ICAO[i]
datos[inds,c('ciudad_destino','provincia_destino','lat_destino','long_destino')] = aeropuertos[i,c("City served","Province","lat","long")]
}
datos = drop_na(datos)
datos$distancia = distHaversine(datos[,c("long_origen","lat_origen")],datos[,c("long_destino","lat_destino")])
